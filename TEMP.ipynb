{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads in Kaggle .csv file of NHL stats and performs initial cleaning\n",
    "def load_data():\n",
    "    names = [\"game_skater_stats\", \"game_plays\", \"game_shifts\", \"game\", \"player_info\", \"team_info\"]\n",
    "    t2 = perf_counter()\n",
    "    df = {}\n",
    "\n",
    "    print(\"load\")\n",
    "    for name in names:\n",
    "        df[name] = pd.read_csv(f\"kaggle_stats/{name}.csv\").drop_duplicates(ignore_index=True)\n",
    "        t1, t2 = t2, perf_counter()\n",
    "        print(f\"{name:>25}: {t2 - t1:.4g} sec, {len(df[name])} rows\")\n",
    "        # return a dict of df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pandas dataframe from a website table given a dictionary of URLs\n",
    "def read_url(urls):\n",
    "    total_dfs = []\n",
    "\n",
    "    for url in urls.keys():\n",
    "        if urls[url] == \"single\":\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = clean_spo_df(df)\n",
    "            total_dfs.append(df)\n",
    "        if urls[url] == \"multi\":\n",
    "            dfs = []\n",
    "            i = \"1\"\n",
    "            df = pd.read_html(url + i)[0]\n",
    "            while len(df) != 0:\n",
    "                df = clean_capfr_df(df)\n",
    "                dfs.append(df)\n",
    "                df = pd.read_html(url + i)[0]\n",
    "                i = int(i)\n",
    "                i += 1\n",
    "                i = str(i)\n",
    "            combined_df = pd.DataFrame()\n",
    "            for df in dfs:\n",
    "                combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            total_dfs.append(combined_df)\n",
    "\n",
    "    return total_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spo_df(df):\n",
    "    df.columns = [\n",
    "        \"Rank\",\n",
    "        \"Team\",\n",
    "        \"Record\",\n",
    "        \"Players Active\",\n",
    "        \"Avg Age Team\",\n",
    "        \"Total Cap Allocations\",\n",
    "        \"Long-Term IR Adjustment\",\n",
    "        \"Cap Space All\",\n",
    "        \"Active\",\n",
    "        \"Injured\",\n",
    "        \"Injured  Long-Term\",\n",
    "    ]\n",
    "    df = df[[\"Rank\", \"Team\", \"Total Cap Allocations\", \"Cap Space All\"]]\n",
    "    df_trimmed = df.iloc[:-2]\n",
    "    return df_trimmed\n",
    "\n",
    "\n",
    "def clean_capfr_df(df):\n",
    "    df = df[[\"PLAYER\", \"TEAM\", \"POS\", \"CAP HIT\", \"SALARY\"]]\n",
    "    # NEW LINES: Splitting \"PLAYER\" Column into first and last names\n",
    "    # Splitting the \"PLAYER\" column based on the first occurrence of a space\n",
    "    df[[\"prefix\", \"firstName\", \"lastName\"]] = df[\"PLAYER\"].str.split(\" \", n=2, expand=True)\n",
    "    # Drop the original \"PLAYER\" column and the \"prefix\" column\n",
    "    df = df.drop(columns=[\"PLAYER\", \"prefix\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaks NHL dataframe down into individual seasons\n",
    "def organize_by_season(seasons, df):\n",
    "    df_orig = df\n",
    "    nhl_dfs = []\n",
    "    for season in seasons:\n",
    "        df = df_orig.copy()\n",
    "        df[\"game\"] = df[\"game\"].query(f\"season == {season}\")\n",
    "        # filter games to just one season\n",
    "        # when we call df, we are actually calling the keys in the dict of df and this is why we can now call df[]as opposed to df_game....\n",
    "        for name in [\"game_skater_stats\", \"game_plays\", \"game_shifts\"]:\n",
    "            # do an inner merge to reduce the number of rows...keeping only the rows where game and game_id match ....\n",
    "            df[name] = pd.merge(df[name], df[\"game\"][[\"game_id\"]], on=\"game_id\")\n",
    "            for key, val in df.items():\n",
    "                print(f\"{key:>25}: {len(val)}\")\n",
    "        # reduce df['game_plays'] df in advance\n",
    "        cols = [\"play_id\", \"game_id\", \"team_id_for\", \"event\", \"time\"]\n",
    "        events = [\"Shot\", \"Blocked Shot\", \"Missed Shot\", \"Goal\"]\n",
    "        # using .loc here as a mask\n",
    "        df[\"game_plays\"] = df[\"game_plays\"].loc[df[\"game_plays\"][\"event\"].isin(events)]\n",
    "        # defining \"time\" col\n",
    "        df[\"game_plays\"][\"time\"] = (\n",
    "            df[\"game_plays\"][\"periodTime\"] + (df[\"game_plays\"][\"period\"] - 1) * 1200\n",
    "        )\n",
    "        df[\"game_plays\"] = df[\"game_plays\"][cols]\n",
    "\n",
    "        print(f\"reduced game_plays num rows: {len(df['game_plays'])}\")\n",
    "\n",
    "        # initialize corsi df\n",
    "        # sort all rows by game_id and on ties defer to player_id... everything with the same game_id will be grouped together\n",
    "        # NEW LINE: Added \"timeonice\"\n",
    "        df_corsi = df[\"game_skater_stats\"].sort_values([\"game_id\", \"player_id\"], ignore_index=True)[\n",
    "            [\"game_id\", \"player_id\", \"team_id\", \"timeOnIce\"]\n",
    "        ]\n",
    "\n",
    "        nhl_dfs.append([season, create_corsi_stats(df_corsi, df)])\n",
    "\n",
    "    return nhl_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a list of pandas dataframes, calculates corsi statistics and adds them to dataframes\n",
    "def create_corsi_stats(df_corsi, df):\n",
    "    df_corsi[[\"CF\", \"CA\", \"C\"]] = np.nan\n",
    "\n",
    "    game_id_prev = None\n",
    "    t1 = perf_counter()\n",
    "    for i, row in df_corsi.iterrows():\n",
    "        game_id, player_id, team_id = row.iloc[:3]\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"{i:>6}/{len(df_corsi)}, {perf_counter() - t1:.2f} s\")\n",
    "        if game_id != game_id_prev:\n",
    "            shifts_game = df[\"game_shifts\"].query(f\"game_id == {game_id}\")\n",
    "            plays_game = df[\"game_plays\"].query(f\"game_id == {game_id}\")\n",
    "        shifts_player = shifts_game.query(f\"player_id == {player_id}\")\n",
    "        mask = (\n",
    "            shifts_game[\"shift_start\"].searchsorted(plays_game[\"time\"])\n",
    "            - shifts_game[\"shift_end\"].searchsorted(plays_game[\"time\"])\n",
    "        ).astype(bool)\n",
    "        plays_player = plays_game[mask]\n",
    "        # mask was it for or against our team. is it for team of the player whose player_id we are looking at\n",
    "        is_our_team = plays_player[\"team_id_for\"] == team_id\n",
    "        is_missed_shot = plays_player[\"event\"] == \"Missed Shot\"\n",
    "        CF = (is_our_team ^ is_missed_shot).sum()\n",
    "        # number of rows in the df\n",
    "        CA = len(plays_player) - CF\n",
    "        C = CF - CA\n",
    "        df_corsi.iloc[i, 4:] = [CF, CA, C]\n",
    "    df_corsi[\"CF_Percent\"] = df_corsi[\"CF\"] / (df_corsi[\"CF\"] + df_corsi[\"CA\"])\n",
    "\n",
    "    # Merging player_info and team_info\n",
    "    # NEW LINE\n",
    "    df_corsi = df_corsi.merge(\n",
    "        df[\"player_info\"][[\"player_id\", \"firstName\", \"lastName\", \"primaryPosition\"]],\n",
    "        on=\"player_id\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # NEW LINE\n",
    "    df_corsi = df_corsi.merge(\n",
    "        df[\"team_info\"][[\"team_id\", \"teamName\", \"abbreviation\"]], on=\"team_id\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    return df_corsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs(season_dfs, salary_dfs):\n",
    "    joined_dfs = []\n",
    "\n",
    "    if len(season_dfs) == len(salary_dfs):\n",
    "        for season_df, salary_df in zip(season_dfs, salary_dfs):\n",
    "            # Merge season_df with salary_df based on firstName and lastName\n",
    "            merged_df = pd.merge(\n",
    "                season_df[1],\n",
    "                salary_df[[\"firstName\", \"lastName\", \"CAP HIT\", \"SALARY\"]],\n",
    "                on=[\"firstName\", \"lastName\"],\n",
    "                how=\"left\",\n",
    "            )\n",
    "\n",
    "            # Append the merged dataframe to joined_dfs\n",
    "            joined_dfs.append([season_df[0], merged_df])\n",
    "\n",
    "    return joined_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes csv files for individual NHL seasons from a list of pandas dataframes\n",
    "def write_csv(dfs):\n",
    "    for df in dfs:\n",
    "        df[1].to_csv(f\"TEMP_corsi_vals/TEMP_Corsi_{df[0]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "        game_skater_stats: 0.5764 sec, 853404 rows\n",
      "               game_plays: 9.232 sec, 4217063 rows\n",
      "              game_shifts: 2.276 sec, 9900705 rows\n",
      "                     game: 0.02991 sec, 23735 rows\n",
      "              player_info: 0.005477 sec, 3925 rows\n",
      "                team_info: 0.0005931 sec, 33 rows\n"
     ]
    }
   ],
   "source": [
    "# Spotrac URLs for team salary totals\n",
    "spo_url_15 = \"https://www.spotrac.com/nhl/cap/_/year/2015/sort/cap_maximum_space2\"\n",
    "spo_url_16 = \"https://www.spotrac.com/nhl/cap/_/year/2016/sort/cap_maximum_space2\"\n",
    "spo_url_17 = \"https://www.spotrac.com/nhl/cap/_/year/2017/sort/cap_maximum_space2\"\n",
    "\n",
    "# Cap Friendly URLs for player salary totals\n",
    "cafr_base_15 = \"https://www.capfriendly.com/browse/active/2016?hide=clauses,age,handed,skater-stats,goalie-stats&pg=\"\n",
    "cafr_base_16 = \"https://www.capfriendly.com/browse/active/2017?hide=clauses,age,handed,skater-stats,goalie-stats&pg=\"\n",
    "cafr_base_17 = \"https://www.capfriendly.com/browse/active/2018?hide=clauses,age,handed,skater-stats,goalie-stats&pg=\"\n",
    "\n",
    "# Loading Kaggle files\n",
    "df_master = load_data()\n",
    "seasons = [20152016, 20162017, 20172018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        game_skater_stats: 47553\n",
      "               game_plays: 4217063\n",
      "              game_shifts: 9900705\n",
      "                     game: 1321\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "        game_skater_stats: 47553\n",
      "               game_plays: 413156\n",
      "              game_shifts: 9900705\n",
      "                     game: 1321\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "        game_skater_stats: 47553\n",
      "               game_plays: 413156\n",
      "              game_shifts: 1039022\n",
      "                     game: 1321\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "reduced game_plays num rows: 144387\n",
      "     0/47553, 0.00 s\n",
      "  1000/47553, 2.56 s\n",
      "  2000/47553, 5.33 s\n",
      "  3000/47553, 8.07 s\n",
      "  4000/47553, 10.78 s\n",
      "  5000/47553, 13.53 s\n",
      "  6000/47553, 16.21 s\n",
      "  7000/47553, 18.98 s\n",
      "  8000/47553, 21.63 s\n",
      "  9000/47553, 24.28 s\n",
      " 10000/47553, 27.18 s\n",
      " 11000/47553, 30.09 s\n",
      " 12000/47553, 32.86 s\n",
      " 13000/47553, 35.57 s\n",
      " 14000/47553, 38.46 s\n",
      " 15000/47553, 41.47 s\n",
      " 16000/47553, 44.13 s\n",
      " 17000/47553, 46.84 s\n",
      " 18000/47553, 49.70 s\n",
      " 19000/47553, 52.56 s\n",
      " 20000/47553, 55.34 s\n",
      " 21000/47553, 58.06 s\n",
      " 22000/47553, 61.14 s\n",
      " 23000/47553, 64.08 s\n",
      " 24000/47553, 66.95 s\n",
      " 25000/47553, 69.64 s\n",
      " 26000/47553, 72.42 s\n",
      " 27000/47553, 75.14 s\n",
      " 28000/47553, 77.92 s\n",
      " 29000/47553, 80.61 s\n",
      " 30000/47553, 83.31 s\n",
      " 31000/47553, 86.17 s\n",
      " 32000/47553, 88.85 s\n",
      " 33000/47553, 91.59 s\n",
      " 34000/47553, 94.39 s\n",
      " 35000/47553, 97.18 s\n",
      " 36000/47553, 99.77 s\n",
      " 37000/47553, 102.33 s\n",
      " 38000/47553, 105.07 s\n",
      " 39000/47553, 107.94 s\n",
      " 40000/47553, 110.74 s\n",
      " 41000/47553, 113.64 s\n",
      " 42000/47553, 116.61 s\n",
      " 43000/47553, 119.49 s\n",
      " 44000/47553, 122.29 s\n",
      " 45000/47553, 125.12 s\n",
      " 46000/47553, 127.94 s\n",
      " 47000/47553, 130.90 s\n",
      "        game_skater_stats: 47406\n",
      "               game_plays: 4217063\n",
      "              game_shifts: 9900705\n",
      "                     game: 1323\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "        game_skater_stats: 47406\n",
      "               game_plays: 418130\n",
      "              game_shifts: 9900705\n",
      "                     game: 1323\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "        game_skater_stats: 47406\n",
      "               game_plays: 418130\n",
      "              game_shifts: 1038248\n",
      "                     game: 1323\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "reduced game_plays num rows: 147700\n",
      "     0/47406, 0.00 s\n",
      "  1000/47406, 2.75 s\n",
      "  2000/47406, 5.61 s\n",
      "  3000/47406, 8.61 s\n",
      "  4000/47406, 11.29 s\n",
      "  5000/47406, 13.97 s\n",
      "  6000/47406, 16.65 s\n",
      "  7000/47406, 19.60 s\n",
      "  8000/47406, 22.52 s\n",
      "  9000/47406, 25.39 s\n",
      " 10000/47406, 28.18 s\n",
      " 11000/47406, 31.12 s\n",
      " 12000/47406, 33.85 s\n",
      " 13000/47406, 36.74 s\n",
      " 14000/47406, 39.65 s\n",
      " 15000/47406, 42.46 s\n",
      " 16000/47406, 45.35 s\n",
      " 17000/47406, 48.35 s\n",
      " 18000/47406, 51.28 s\n",
      " 19000/47406, 54.14 s\n",
      " 20000/47406, 56.93 s\n",
      " 21000/47406, 59.84 s\n",
      " 22000/47406, 62.62 s\n",
      " 23000/47406, 65.39 s\n",
      " 24000/47406, 68.31 s\n",
      " 25000/47406, 71.29 s\n",
      " 26000/47406, 74.11 s\n",
      " 27000/47406, 76.85 s\n",
      " 28000/47406, 79.51 s\n",
      " 29000/47406, 82.39 s\n",
      " 30000/47406, 85.20 s\n",
      " 31000/47406, 87.81 s\n",
      " 32000/47406, 90.39 s\n",
      " 33000/47406, 93.15 s\n",
      " 34000/47406, 96.04 s\n",
      " 35000/47406, 98.84 s\n",
      " 36000/47406, 101.38 s\n",
      " 37000/47406, 104.00 s\n",
      " 38000/47406, 107.00 s\n",
      " 39000/47406, 109.94 s\n",
      " 40000/47406, 112.60 s\n",
      " 41000/47406, 115.27 s\n",
      " 42000/47406, 118.02 s\n",
      " 43000/47406, 120.93 s\n",
      " 44000/47406, 123.67 s\n",
      " 45000/47406, 126.36 s\n",
      " 46000/47406, 129.03 s\n",
      " 47000/47406, 131.88 s\n",
      "        game_skater_stats: 48780\n",
      "               game_plays: 4217063\n",
      "              game_shifts: 9900705\n",
      "                     game: 1363\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "        game_skater_stats: 48780\n",
      "               game_plays: 435851\n",
      "              game_shifts: 9900705\n",
      "                     game: 1363\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "        game_skater_stats: 48780\n",
      "               game_plays: 435851\n",
      "              game_shifts: 1048261\n",
      "                     game: 1363\n",
      "              player_info: 3925\n",
      "                team_info: 33\n",
      "reduced game_plays num rows: 157169\n",
      "     0/48780, 0.00 s\n",
      "  1000/48780, 2.79 s\n",
      "  2000/48780, 5.56 s\n",
      "  3000/48780, 8.23 s\n",
      "  4000/48780, 10.95 s\n",
      "  5000/48780, 13.88 s\n",
      "  6000/48780, 16.63 s\n",
      "  7000/48780, 19.33 s\n",
      "  8000/48780, 22.27 s\n",
      "  9000/48780, 25.22 s\n",
      " 10000/48780, 28.03 s\n",
      " 11000/48780, 30.99 s\n",
      " 12000/48780, 33.82 s\n",
      " 13000/48780, 36.58 s\n",
      " 14000/48780, 39.39 s\n",
      " 15000/48780, 42.35 s\n",
      " 16000/48780, 45.09 s\n",
      " 17000/48780, 48.08 s\n",
      " 18000/48780, 50.89 s\n",
      " 19000/48780, 53.68 s\n",
      " 20000/48780, 56.31 s\n",
      " 21000/48780, 59.26 s\n",
      " 22000/48780, 62.03 s\n",
      " 23000/48780, 64.86 s\n",
      " 24000/48780, 67.92 s\n",
      " 25000/48780, 70.96 s\n",
      " 26000/48780, 73.86 s\n",
      " 27000/48780, 76.82 s\n",
      " 28000/48780, 79.53 s\n",
      " 29000/48780, 82.24 s\n",
      " 30000/48780, 85.09 s\n",
      " 31000/48780, 88.03 s\n",
      " 32000/48780, 90.87 s\n",
      " 33000/48780, 93.55 s\n",
      " 34000/48780, 96.38 s\n",
      " 35000/48780, 99.09 s\n",
      " 36000/48780, 101.65 s\n",
      " 37000/48780, 104.49 s\n",
      " 38000/48780, 107.27 s\n",
      " 39000/48780, 110.05 s\n",
      " 40000/48780, 112.92 s\n",
      " 41000/48780, 115.67 s\n",
      " 42000/48780, 118.41 s\n",
      " 43000/48780, 121.25 s\n",
      " 44000/48780, 123.97 s\n",
      " 45000/48780, 126.92 s\n",
      " 46000/48780, 129.73 s\n",
      " 47000/48780, 132.67 s\n",
      " 48000/48780, 135.88 s\n"
     ]
    }
   ],
   "source": [
    "nhl_dfs = organize_by_season(seasons, df_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhl_urls = {\n",
    "    spo_url_15: \"single\",\n",
    "    spo_url_16: \"single\",\n",
    "    spo_url_17: \"single\",\n",
    "    cafr_base_15: \"multi\",\n",
    "    cafr_base_16: \"multi\",\n",
    "    cafr_base_17: \"multi\",\n",
    "}\n",
    "\n",
    "\n",
    "team_sals_15, team_sals_16, team_sals_17, player_sals_15, player_sals_16, player_sals_17 = read_url(\n",
    "    nhl_urls\n",
    ")\n",
    "\n",
    "dfs = [\n",
    "    [\"team\", \"20151016\", team_sals_15],\n",
    "    [\"team\", \"20162017\", team_sals_16],\n",
    "    [\"team\", \"20171018\", team_sals_17],\n",
    "    [\"player\", \"20151016\", player_sals_15],\n",
    "    [\"player\", \"20161017\", player_sals_16],\n",
    "    [\"player\", \"20171018\", player_sals_17],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_dfs = [player_sals_15, player_sals_16, player_sals_17]\n",
    "final_dfs = join_dfs(nhl_dfs, salary_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv(final_dfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
